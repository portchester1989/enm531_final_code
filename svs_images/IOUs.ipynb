{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import openslide\n",
    "import sys\n",
    "import imgaug.augmenters as iaa\n",
    "#sys.path.append('../brown-datathon/src')\n",
    "from config import Config\n",
    "from models.scse_pyramid_unet import UNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred, target, n_classes=2):\n",
    "    ious = []\n",
    "    #pred = torch.round(pred.view(-1)).long()\n",
    "    pred = pred.ravel()\n",
    "    \n",
    "\n",
    "    # Ignore IoU for background class (\"0\")\n",
    "    for cls in range(0, n_classes):  # This goes from 1:n_classes-1 -> class \"0\" is ignored\n",
    "        this_target = np.squeeze(target[:,:,cls])\n",
    "        this_target = this_target.ravel()\n",
    "        pred_inds = pred == (cls + 1)\n",
    "        target_inds = this_target == 1\n",
    "        # Cast to long to prevent overflows       \n",
    "        intersection = len(this_target[pred_inds & target_inds])  \n",
    "        union = len(pred[pred_inds]) + len(this_target[target_inds]) - \\\n",
    "                intersection\n",
    "\n",
    "        if union == 0:\n",
    "            ious.append(0.)  # If there is no ground truth, do not include in evaluation\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(max(union, 1)))\n",
    "    return ious\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = openslide.OpenSlide('285383.svs')\n",
    "whole_region = reader.read_region((0,0),1,reader.level_dimensions[1])\n",
    "whole_region = np.array(whole_region.getdata()).reshape(*reader.level_dimensions[1][::-1],4)[:,:,:3]\n",
    "bbox = pd.read_csv('285383.csv')\n",
    "tangle_threads = bbox[bbox['label'].isin(['tangle','threads'])]\n",
    "top_left = np.floor(tangle_threads[['x','y']]).astype(np.uint32).values\n",
    "bottom_right = np.ceil(tangle_threads[['x','y']].values + tangle_threads[['w','h']].values).astype(np.uint32)\n",
    "label = np.where(tangle_threads['label'] == 'tangle',1,2)\n",
    "mask = np.zeros_like(whole_region[:,:,:2])\n",
    "for i in range(2):\n",
    "     this_top_left = top_left[label == (i + 1)]\n",
    "     this_bottom_right = bottom_right[label == (i + 1)]\n",
    "     for j,tl in enumerate(this_top_left):\n",
    "            br = this_bottom_right[j]\n",
    "            mask[tl[1]:br[1],tl[0]:br[0],i] = 1\n",
    "padder = iaa.PadToFixedSize(512,512,position='right-bottom',pad_cval=255)\n",
    "patches = []\n",
    "for i in range(whole_region.shape[0] // 512 + 1):\n",
    "    for j in range(whole_region.shape[1] // 512 + 1):\n",
    "        patch = whole_region[i * 512: (i + 1) * 512,j * 512: (j + 1) * 512] \n",
    "        if i == whole_region.shape[0] // 512  or j == whole_region.shape[1] // 512 :\n",
    "            patch = padder.augment_image(patch)\n",
    "        patch = patch / 255\n",
    "        patches.append(patch) \n",
    "input_patches = np.transpose(np.stack(patches),(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith torch.no_grad():\\n    model.eval()\\n    output = model(torch.from_numpy(t_region).float().to(device))\\n    pred = torch.squeeze(torch.argmax(output,1).long()).cpu().data.numpy()\\n    conts = []\\n    for cl in range(2):\\n        pred[pred != (cl + 1)] = 0\\n        contours, hierarchy = cv2.findContours(pred.astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\\n        conts.append(contours)\\n        #y,x = np.mgrid[0:512,0:512]\\n        #coord = np.vstack([x.ravel(),y.ravel()]).T\\n        #print(x[pred == (cl + 1)])\\n        #print(y[pred == (cl + 1)])\\n        #print([np.min(pred[:, 1]) - 1, np.min(pred[:, 2]) - 1, np.max(pred[:, 1])+1,np.max(pred[:, 2]) + 1])\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list = ['no_shake_drop_no_deepcut','with_shake_drop_no_deepcut','no_shake_drop_deepcut','shake_drop_deepcut']\n",
    "device = torch.device('cuda')\n",
    "ious = []\n",
    "for i,model in enumerate(models_list):\n",
    "    shake_drop = False if i % 2 == 0 else True\n",
    "    model = UNet(84, 3, 3,\n",
    "            shake_drop, True, 4, 2)\n",
    "    model = model.to(device)\n",
    "    checkpoint = torch.load('../brown-datathon/src/training_logs/' + model + '/best.pth.tar')\n",
    "    model.load_state_dict(checkpoint.state_dict())\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(whole_region.shape[1] // 512 + 1):\n",
    "            this_patches = torch.from_numpy(input_patches[i * (whole_region.shape[1] // 512 + 1):(i + 1) * (whole_region.shape[1] // 512 + 1)]).float().to(device)\n",
    "            output = model(this_patches)\n",
    "            pred = torch.argmax(output,1).long().cpu().data.numpy()\n",
    "            preds.append(pred)\n",
    "            this_patches.to('cpu')\n",
    "            del this_patches\n",
    "    catted = np.concatenate(preds)\n",
    "    recon_mask = np.vstack([np.hstack(catted[i * (whole_region.shape[1] // 512 + 1): (i + 1) * (whole_region.shape[1] // 512 + 1)]) for i in range(whole_region.shape[0] // 512 + 1)])\n",
    "    recon_mask = recon_mask[:reader.level_dimensions[1][1],:reader.level_dimensions[1][0]]\n",
    "    ious.append(iou(recon_mask,mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
