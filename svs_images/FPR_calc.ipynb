{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import openslide\n",
    "import sys\n",
    "import imgaug.augmenters as iaa\n",
    "sys.path.append('../brown-datathon/src')\n",
    "from config import Config\n",
    "from models.scse_pyramid_unet import UNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = openslide.OpenSlide('285317.svs')\n",
    "whole_region = reader.read_region((0,0),1,reader.level_dimensions[1])\n",
    "whole_region = np.array(whole_region.getdata()).reshape(*reader.level_dimensions[1][::-1],4)[:,:,:3]\n",
    "patches = []\n",
    "padder = iaa.PadToFixedSize(512,512,position='right-bottom',pad_cval=255)\n",
    "for i in range(whole_region.shape[0] // 512 + 1):\n",
    "    for j in range(whole_region.shape[1] // 512 + 1):\n",
    "        patch = whole_region[i * 512: (i + 1) * 512,j * 512: (j + 1) * 512] \n",
    "        if i == whole_region.shape[0] // 512  or j == whole_region.shape[1] // 512 :\n",
    "            patch = padder.augment_image(patch)\n",
    "        patch = patch / 255\n",
    "        patches.append(patch) \n",
    "input_patches = np.transpose(np.stack(patches),(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith torch.no_grad():\\n    model.eval()\\n    output = model(torch.from_numpy(t_region).float().to(device))\\n    pred = torch.squeeze(torch.argmax(output,1).long()).cpu().data.numpy()\\n    conts = []\\n    for cl in range(2):\\n        pred[pred != (cl + 1)] = 0\\n        contours, hierarchy = cv2.findContours(pred.astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\\n        conts.append(contours)\\n        #y,x = np.mgrid[0:512,0:512]\\n        #coord = np.vstack([x.ravel(),y.ravel()]).T\\n        #print(x[pred == (cl + 1)])\\n        #print(y[pred == (cl + 1)])\\n        #print([np.min(pred[:, 1]) - 1, np.min(pred[:, 2]) - 1, np.max(pred[:, 1])+1,np.max(pred[:, 2]) + 1])\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config = Config()\n",
    "models_list = ['no_shake_drop_no_deepcut','with_shake_drop_no_deepcut','no_shake_drop_deepcut','shake_drop_deepcut']\n",
    "device = torch.device('cuda')\n",
    "fprs = []\n",
    "for i,model in enumerate(models_list):\n",
    "    shake_drop = False if i % 2 == 0 else True\n",
    "    model = UNet(84, 3, 3,\n",
    "            shake_drop, True, 4, 2)\n",
    "    model = model.to(device)\n",
    "    checkpoint = torch.load('../brown-datathon/src/training_logs/' + model + '/best.pth.tar')\n",
    "    model.load_state_dict(checkpoint.state_dict())\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i in range(66):\n",
    "            this_patches = torch.from_numpy(input_patches[i * 20:(i + 1) * 20]).float().to(device)\n",
    "            output = model(this_patches)\n",
    "            pred = torch.argmax(output,1).long().cpu().data.numpy()\n",
    "            preds.append(pred)\n",
    "            this_patches.to('cpu')\n",
    "            del this_patches\n",
    "    catted = np.concatenate(preds)\n",
    "    recon_mask = np.vstack([np.hstack(catted[i * 42: (i + 1) * 42]) for i in range(31)])\n",
    "    recon_mask = recon_mask[:reader.level_dimensions[1][1],:reader.level_dimensions[1][0]]\n",
    "    fprs.append(len(recon_mask[recon_mask != 0]) / (np.prod(reader.level_dimensions[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = pd.read_csv('285317.csv')\n",
    "v_tau = bbox[bbox['label'] == 'vessel_tau']\n",
    "np.flip(np.ceil(v_tau[['w','h']].values)).astype(np.uint32)\n",
    "ves_region = reader.read_region(tuple(*np.floor(v_tau[['x','y']].values).astype(np.uint32)),0,tuple(*np.ceil(v_tau[['w','h']].values).astype(np.uint32)))\n",
    "ves_region = np.array(ves_region.getdata()).reshape(*np.flip(*np.ceil(v_tau[['w','h']].values).astype(np.uint32)),4)[:,:,:3]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(ves_region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
